{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOeFomUErrZ0"
      },
      "outputs": [],
      "source": [
        "!pip install transformers sentencepiece datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import PegasusTokenizer, PegasusForConditionalGeneration"
      ],
      "metadata": {
        "id": "sGwV6VFIsCLg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"banking77\")"
      ],
      "metadata": {
        "id": "AHUFezTFsPwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(text, min_output_length=20, max_output_length=25):\n",
        "    model_name = \"human-centered-summarization/financial-summarization-pegasus\"\n",
        "    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "    model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"longest\", max_length=512)\n",
        "    summary_ids = model.generate(inputs[\"input_ids\"], num_return_sequences=1, num_beams=5, length_penalty=0.8, min_length=min_output_length, max_length=max_output_length)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary"
      ],
      "metadata": {
        "id": "vCo8RsUwsZat"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the dataset by the length of the customer texts\n",
        "sorted_data = sorted(dataset['train'], key=lambda x: len(x['text']), reverse=True)\n",
        "\n",
        "# Extract the longest 5 customer texts\n",
        "longest_five_texts = [entry[\"text\"] for entry in sorted_data[:5]]"
      ],
      "metadata": {
        "id": "0faduiH_SROi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(longest_five_texts)):\n",
        "      print(f\"Longest Customer Text {i} (Length: {len(longest_five_texts[i])}): {longest_five_texts[i]}\")\n",
        "      summerised_text = summarize(longest_five_texts[i])\n",
        "      print(f\"summerised_text: \", i , \"is \" , summerised_text)"
      ],
      "metadata": {
        "id": "g1KFW5wnSogX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}